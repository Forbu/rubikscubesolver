{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# chose the current file directory as the working directory\n",
    "import os\n",
    "os.chdir(\"/teamspace/studios/this_studio/rubikscubesolver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "cuda_plugin_extension is not found.\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pickle\n",
    "\n",
    "import wandb  # for logging\n",
    "import time\n",
    "from dataclasses import dataclass\n",
    "\n",
    "import jax\n",
    "import jax.numpy as jnp\n",
    "import flax.nnx as nnx\n",
    "\n",
    "import rubiktransformer.dataset as dataset\n",
    "from rubiktransformer.trainer import reshape_sample\n",
    "\n",
    "from rubiktransformer.trainer_online import init_model_optimizer, init_buffer, train_step_transformer_rf, training_loop\n",
    "from rubiktransformer.online_training_utils import run_n_steps, reshape_diffusion_setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mforbu14\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "wandb version 0.17.9 is available!  To upgrade, please run:\n",
       " $ pip install wandb --upgrade"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Tracking run with wandb version 0.17.5"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Run data is saved locally in <code>/teamspace/studios/this_studio/rubikscubesolver/wandb/run-20240907_070127-izga5ebf</code>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "Syncing run <strong><a href='https://wandb.ai/forbu14/RubikTransformer/runs/izga5ebf' target=\"_blank\">experiment_20240907-070126</a></strong> to <a href='https://wandb.ai/forbu14/RubikTransformer' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View project at <a href='https://wandb.ai/forbu14/RubikTransformer' target=\"_blank\">https://wandb.ai/forbu14/RubikTransformer</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       " View run at <a href='https://wandb.ai/forbu14/RubikTransformer/runs/izga5ebf' target=\"_blank\">https://wandb.ai/forbu14/RubikTransformer/runs/izga5ebf</a>"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<button onClick=\"this.nextSibling.style.display='block';this.style.display='none';\">Display W&B run</button><iframe src='https://wandb.ai/forbu14/RubikTransformer/runs/izga5ebf?jupyter=true' style='border:none;width:100%;height:420px;display:none;'></iframe>"
      ],
      "text/plain": [
       "<wandb.sdk.wandb_run.Run at 0x7f09bc76a6b0>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "@dataclass\n",
    "class Config:\n",
    "    \"\"\"Configuration class\"\"\"\n",
    "\n",
    "    jax_key: jnp.ndarray = jax.random.PRNGKey(49)\n",
    "    rngs = nnx.Rngs(48)\n",
    "    batch_size: int = 128\n",
    "    lr_1: float = 4e-4\n",
    "    lr_2: float = 4e-4\n",
    "    nb_games: int = 128 * 100\n",
    "    len_seq: int = 32\n",
    "    nb_step: int = 1000000\n",
    "    max_length_buffer: int = 1024 * 10\n",
    "    log_every_step: int = 10\n",
    "    log_eval_every_step: int = 10\n",
    "    log_policy_reward_every_step: int = 10\n",
    "    add_data_every_step: int = 500\n",
    "\n",
    "    save_model_every_step: int = 2000\n",
    "\n",
    "\n",
    "config = Config()\n",
    "\n",
    "# init wandb config\n",
    "user = \"forbu14\"\n",
    "project = \"RubikTransformer\"\n",
    "display_name = \"experiment_\" + time.strftime(\"%Y%m%d-%H%M%S\")\n",
    "\n",
    "wandb.init(entity=user, project=project, name=display_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "(\n",
    "    optimizer_diffuser,\n",
    "    optimizer_inverse,\n",
    "    metrics_train,\n",
    "    metrics_eval,\n",
    "    metrics_inverse,\n",
    "    transformer,\n",
    "    inverse_rl_model,\n",
    ") = init_model_optimizer(config)\n",
    "\n",
    "env, buffer, buffer_eval, buffer_list, buffer_list_eval, jit_step = init_buffer(\n",
    "    config\n",
    ")\n",
    "\n",
    "vmap_reset = jax.vmap(jax.jit(env.reset))\n",
    "vmap_step = jax.vmap(run_n_steps, in_axes=(0, 0, None))\n",
    "\n",
    "##### TRAINING #####\n",
    "key, subkey = jax.random.split(config.jax_key)\n",
    "config.jax_key = key\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "buffer, buffer_list = dataset.fast_gathering_data_diffusion(\n",
    "    env,\n",
    "    vmap_reset,\n",
    "    vmap_step,\n",
    "    config.nb_games * 1,  # old is int(config.nb_games * 10.0),\n",
    "    config.len_seq,\n",
    "    buffer,\n",
    "    buffer_list,\n",
    "    subkey,\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load weight from world model transformer:\n",
    "import pickle\n",
    "\n",
    "filename = \"state_ddt_model_improved_v2.pickle\"\n",
    "\n",
    "with open(filename, \"rb\") as input_file:\n",
    "    state = pickle.load(input_file)\n",
    "\n",
    "nnx.update(transformer, state)\n",
    "\n",
    "# load weight from world model transformer:\n",
    "import pickle\n",
    "\n",
    "filename = \"state_inverse_rl_model_improved_v2.pickle\"\n",
    "\n",
    "with open(filename, \"rb\") as input_file:\n",
    "    state = pickle.load(input_file)\n",
    "\n",
    "nnx.update(inverse_rl_model, state)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "sample = buffer.sample(buffer_list, subkey)\n",
    "sample = reshape_diffusion_setup(sample)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict_keys(['action', 'reward', 'state_histo', 'time_step', 'context', 'state_past', 'state_future', 'state_future_noise', 'action_inverse', 'state_histo_inverse_t', 'state_histo_inverse_td1'])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.keys()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0., 1., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 1., ..., 1., 0., 0.],\n",
       "       [0., 1., 0., ..., 1., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"action_inverse\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0., 0., ..., 1., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       ...,\n",
       "       [1., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"state_histo_inverse_t\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 1., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]], dtype=float32)"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample[\"state_histo_inverse_td1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[-58.14122  , -12.908836 , 107.829445 , -26.21095  , -87.36493  ,\n",
       "        -19.743734 ],\n",
       "       [-17.515263 ,  80.81346  , -28.577995 , -49.040886 , -30.555523 ,\n",
       "        -17.010876 ],\n",
       "       [-30.758236 , -30.516747 ,  76.49304  , -14.1797085, -48.68231  ,\n",
       "        -10.990468 ],\n",
       "       ...,\n",
       "       [-23.25964  , -62.139297 , -24.637434 ,  67.35371  , -12.765332 ,\n",
       "        -13.466367 ],\n",
       "       [-33.95061  , -17.303339 ,  73.70761  , -25.77107  , -45.953106 ,\n",
       "        -11.735286 ],\n",
       "       [-15.208434 ,  78.16751  , -26.444832 , -57.60352  , -29.599823 ,\n",
       "        -18.02725  ]], dtype=float32)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inverse_rl_model(sample[\"state_histo_inverse_t\"], sample[\"state_histo_inverse_td1\"])[:, :6]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def sampling_model(key, model, sample_eval, nb_step=100, config=None, target_reward=0.5):\n",
    "    \"\"\"\n",
    "    Function used to sampling a state from a list \n",
    "    \"\"\"\n",
    "    seq_len_future = config.len_seq - config.len_seq // 4 \n",
    "    noise_future  = jax.random.dirichlet(key, jnp.ones(6) * 5., (config.batch_size, seq_len_future, 54))\n",
    "    sample_eval[\"reward\"] = jnp.linspace(start=-0.1 + target_reward, stop=0.1 + target_reward, num=config.batch_size)[:, None]\n",
    "\n",
    "    for t_step in range(nb_step):\n",
    "        t_step_array = jnp.ones((config.batch_size, 1, 1, 1)) * float(t_step / nb_step)\n",
    "        sample_eval[\"context\"] = jnp.concatenate([sample_eval[\"reward\"], t_step_array[:, :, 0, 0]], axis=1)\n",
    "\n",
    "        estimation_logits_past, estimation_logits_future = model(\n",
    "            sample_eval[\"state_past\"], noise_future, sample_eval[\"context\"]\n",
    "        )\n",
    "\n",
    "        estimation_proba_future = jax.nn.softmax(estimation_logits_future, axis=-1)\n",
    "\n",
    "        noise_future = noise_future + float(1. / nb_step) * 1./ (1. - t_step_array + 0.0001) * (estimation_proba_future - noise_future)\n",
    "\n",
    "    return noise_future\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "key, subkey = jax.random.split(config.jax_key)\n",
    "config.jax_key = key\n",
    "\n",
    "buffer_eval, buffer_list_eval = dataset.fast_gathering_data_diffusion(\n",
    "    env,\n",
    "    vmap_reset,\n",
    "    vmap_step,\n",
    "    int(config.batch_size),\n",
    "    config.len_seq,\n",
    "    buffer_eval,\n",
    "    buffer_list_eval,\n",
    "    subkey,\n",
    ")\n",
    "\n",
    "sample = buffer_eval.sample(buffer_list_eval, subkey)\n",
    "sample = reshape_diffusion_setup(sample, subkey)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[[9.99899507e-01, 1.74097950e-05, 1.12622511e-05,\n",
       "          2.68227886e-05, 1.88681297e-05, 2.61575915e-05],\n",
       "         [9.99913096e-01, 2.75000930e-05, 7.84196891e-06,\n",
       "          1.92100415e-05, 1.67725375e-05, 1.56341121e-05],\n",
       "         [1.78341288e-05, 1.04047358e-05, 1.42740319e-05,\n",
       "          1.43313082e-05, 2.53261533e-05, 9.99917805e-01],\n",
       "         ...,\n",
       "         [1.94137683e-05, 1.77902402e-05, 1.11241825e-05,\n",
       "          9.99910533e-01, 2.41212547e-05, 1.69395935e-05],\n",
       "         [2.44495459e-05, 9.99926388e-01, 8.33871309e-06,\n",
       "          8.53434904e-06, 8.80047446e-06, 2.35179905e-05],\n",
       "         [1.31488778e-05, 7.83847645e-06, 9.99915063e-01,\n",
       "          2.54756305e-05, 1.83007214e-05, 2.02064402e-05]],\n",
       "\n",
       "        [[9.99909103e-01, 1.27787935e-05, 2.79305968e-05,\n",
       "          2.04902608e-05, 9.05554043e-06, 2.06260011e-05],\n",
       "         [3.59257683e-05, 1.37771713e-05, 1.21578341e-05,\n",
       "          9.99911845e-01, 1.76803442e-05, 8.60699220e-06],\n",
       "         [2.35249754e-05, 9.04168701e-06, 1.80833740e-05,\n",
       "          2.65468843e-05, 9.99907732e-01, 1.50157139e-05],\n",
       "         ...,\n",
       "         [1.75202731e-05, 1.68021070e-05, 9.33517003e-06,\n",
       "          1.74046727e-05, 1.76896574e-05, 9.99921262e-01],\n",
       "         [2.73061451e-05, 1.67532125e-05, 1.26669183e-05,\n",
       "          1.86183024e-05, 9.99914765e-01, 9.85851511e-06],\n",
       "         [1.54871959e-05, 9.99902487e-01, 3.02868430e-05,\n",
       "          2.15347391e-05, 2.38164794e-05, 6.41838415e-06]],\n",
       "\n",
       "        [[9.99922097e-01, 1.69122359e-05, 1.83767406e-05,\n",
       "          1.09386165e-05, 1.38587784e-05, 1.78767368e-05],\n",
       "         [9.99918997e-01, 1.72946602e-05, 1.41023193e-05,\n",
       "          2.28153076e-05, 2.37543136e-05, 3.03992420e-06],\n",
       "         [1.89208658e-05, 1.59940682e-05, 1.42565696e-05,\n",
       "          1.34125585e-05, 2.25354452e-05, 9.99914885e-01],\n",
       "         ...,\n",
       "         [1.39222248e-05, 1.11710979e-05, 1.96830370e-05,\n",
       "          9.99903798e-01, 2.24234536e-05, 2.89953314e-05],\n",
       "         [1.16017181e-05, 9.99907851e-01, 1.85016543e-05,\n",
       "          4.04072925e-05, 1.21364137e-05, 9.49756941e-06],\n",
       "         [1.72498403e-05, 2.22413801e-05, 9.99908209e-01,\n",
       "          1.77943148e-05, 1.18487515e-05, 2.26476695e-05]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.10528960e-05, 1.99114438e-05, 1.90205174e-05,\n",
       "          1.20810000e-05, 9.99901414e-01, 2.65743583e-05],\n",
       "         [1.81902433e-05, 1.90692954e-05, 2.66891439e-05,\n",
       "          1.72223663e-05, 1.71391293e-05, 9.99901652e-01],\n",
       "         [9.99823153e-01, 1.08733017e-04, 1.14669092e-05,\n",
       "          1.38466712e-05, 1.91868749e-05, 2.35703774e-05],\n",
       "         ...,\n",
       "         [2.31377780e-05, 1.37756579e-05, 9.79553442e-06,\n",
       "          9.99903977e-01, 2.53629405e-05, 2.39096116e-05],\n",
       "         [1.54168811e-05, 9.99902546e-01, 1.70791754e-05,\n",
       "          2.58644577e-05, 2.81878747e-05, 1.09042739e-05],\n",
       "         [2.00994546e-05, 2.67822761e-05, 9.99900877e-01,\n",
       "          2.42085662e-05, 7.76984962e-06, 2.03344971e-05]],\n",
       "\n",
       "        [[2.06145924e-05, 9.99907255e-01, 7.71495979e-06,\n",
       "          2.59089284e-05, 1.56195601e-05, 2.29692087e-05],\n",
       "         [1.06444350e-05, 1.60894124e-05, 2.49014702e-05,\n",
       "          1.57594914e-05, 2.22595409e-05, 9.99910295e-01],\n",
       "         [9.99852002e-01, 7.53713539e-05, 1.63272489e-05,\n",
       "          1.40245538e-05, 2.41997186e-05, 1.80418137e-05],\n",
       "         ...,\n",
       "         [1.33493450e-05, 1.01980986e-05, 6.93649054e-06,\n",
       "          9.99914944e-01, 2.65766867e-05, 2.80749518e-05],\n",
       "         [2.18406785e-05, 9.99915600e-01, 1.07212691e-05,\n",
       "          1.10998517e-05, 2.49610748e-05, 1.57700852e-05],\n",
       "         [1.84124801e-05, 2.60050874e-05, 9.99904037e-01,\n",
       "          2.43554823e-05, 1.37697207e-05, 1.35489972e-05]],\n",
       "\n",
       "        [[2.45671254e-05, 1.78572955e-05, 2.19002832e-05,\n",
       "          3.80235724e-05, 9.99874532e-01, 2.30481382e-05],\n",
       "         [1.90730207e-05, 1.73867447e-05, 1.09215034e-05,\n",
       "          1.94088789e-05, 2.19040085e-05, 9.99911308e-01],\n",
       "         [9.99900818e-01, 1.48004619e-05, 1.82038639e-05,\n",
       "          1.93718588e-05, 1.86261022e-05, 2.81918328e-05],\n",
       "         ...,\n",
       "         [1.68239931e-05, 2.80353706e-05, 1.79602066e-05,\n",
       "          9.99899268e-01, 1.81044452e-05, 1.98381022e-05],\n",
       "         [1.90662686e-05, 9.99910951e-01, 1.43260695e-05,\n",
       "          1.40408520e-05, 2.42886599e-05, 1.73903536e-05],\n",
       "         [1.74748711e-05, 1.51721761e-05, 9.99909222e-01,\n",
       "          1.15159201e-05, 2.22907402e-05, 2.42961105e-05]]],\n",
       "\n",
       "\n",
       "       [[[1.31081324e-05, 1.58637995e-05, 9.99913931e-01,\n",
       "          2.49298755e-05, 1.11983391e-05, 2.09778082e-05],\n",
       "         [2.81559769e-05, 1.26864761e-05, 9.00385203e-06,\n",
       "          1.51296845e-05, 1.68059487e-05, 9.99918282e-01],\n",
       "         [1.60995405e-05, 9.99929607e-01, 2.44202092e-05,\n",
       "          9.07434151e-06, 6.67909626e-06, 1.43370125e-05],\n",
       "         ...,\n",
       "         [2.26814300e-05, 4.08205669e-05, 7.14825001e-06,\n",
       "          9.99901175e-01, 2.30106525e-05, 5.24969073e-06],\n",
       "         [6.09533163e-06, 1.01979822e-05, 9.99917150e-01,\n",
       "          3.03294510e-05, 2.56760977e-05, 1.06467633e-05],\n",
       "         [2.88458541e-05, 6.88369619e-06, 4.84037446e-06,\n",
       "          9.99914706e-01, 2.40083318e-05, 2.07603443e-05]],\n",
       "\n",
       "        [[9.99910712e-01, 2.66409479e-05, 1.78983901e-05,\n",
       "          1.04298815e-05, 2.04693060e-05, 1.39162876e-05],\n",
       "         [2.53596809e-05, 1.43114012e-05, 1.16045121e-05,\n",
       "          1.93376327e-05, 1.86018879e-05, 9.99910712e-01],\n",
       "         [5.91785647e-06, 9.99912024e-01, 1.49278203e-05,\n",
       "          2.46455893e-05, 3.23366839e-05, 1.01816840e-05],\n",
       "         ...,\n",
       "         [1.15151051e-05, 2.04150565e-05, 1.10778492e-05,\n",
       "          2.52006575e-05, 1.43927755e-05, 9.99917388e-01],\n",
       "         [1.52606517e-05, 1.24180224e-05, 9.99908149e-01,\n",
       "          1.61379576e-05, 3.08838207e-05, 1.72115397e-05],\n",
       "         [9.99904394e-01, 3.57490499e-05, 2.55878549e-05,\n",
       "          1.29613327e-05, 1.12936832e-05, 1.00290636e-05]],\n",
       "\n",
       "        [[2.30604783e-05, 2.62896065e-05, 9.99895513e-01,\n",
       "          2.06221594e-05, 2.02297233e-05, 1.43084908e-05],\n",
       "         [1.59681076e-05, 1.19389733e-05, 1.86376274e-05,\n",
       "          3.03331763e-05, 1.11270929e-05, 9.99912024e-01],\n",
       "         [9.13615804e-06, 9.99899805e-01, 1.36664603e-05,\n",
       "          1.74127053e-05, 2.04648823e-05, 3.96040268e-05],\n",
       "         ...,\n",
       "         [1.83000229e-05, 9.80871264e-05, 1.77158508e-05,\n",
       "          9.99828219e-01, 2.32192688e-05, 1.44168735e-05],\n",
       "         [2.27235723e-05, 2.34011095e-05, 9.99912381e-01,\n",
       "          1.57565810e-05, 1.71080464e-05, 8.70012445e-06],\n",
       "         [1.16809970e-05, 2.10301951e-05, 2.04306561e-05,\n",
       "          9.99913454e-01, 1.11091649e-05, 2.23233365e-05]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.27880664e-05, 2.21894588e-05, 9.99908507e-01,\n",
       "          3.77416145e-05, 2.83826375e-06, 5.97094186e-06],\n",
       "         [1.37162860e-05, 1.66430837e-05, 1.81987416e-05,\n",
       "          1.21567864e-05, 1.99652277e-05, 9.99919295e-01],\n",
       "         [1.26628438e-05, 9.99910355e-01, 2.67068390e-05,\n",
       "          1.99277420e-05, 1.32819405e-05, 1.71633437e-05],\n",
       "         ...,\n",
       "         [1.47003448e-05, 2.58637592e-05, 1.78340124e-05,\n",
       "          9.99913216e-01, 1.53176952e-05, 1.30374683e-05],\n",
       "         [1.71789434e-05, 2.63494439e-05, 9.99902844e-01,\n",
       "          1.98055059e-05, 1.30790286e-05, 2.07424164e-05],\n",
       "         [2.54276674e-05, 2.15140171e-05, 7.45028956e-06,\n",
       "          9.99914110e-01, 1.65737001e-05, 1.49750849e-05]],\n",
       "\n",
       "        [[1.49555271e-05, 2.06532422e-05, 9.99907315e-01,\n",
       "          1.41712371e-05, 1.19995093e-05, 3.08926683e-05],\n",
       "         [1.11694681e-05, 2.11729202e-05, 2.73915939e-05,\n",
       "          1.34644797e-05, 1.47641404e-05, 9.99912024e-01],\n",
       "         [1.49089610e-05, 9.99910295e-01, 3.27159651e-05,\n",
       "          1.52586726e-05, 8.88475915e-06, 1.80290081e-05],\n",
       "         ...,\n",
       "         [2.46344134e-05, 1.23583013e-05, 5.87751856e-06,\n",
       "          9.99914110e-01, 1.37279276e-05, 2.93052290e-05],\n",
       "         [2.63196416e-05, 2.14981847e-05, 9.99915481e-01,\n",
       "          1.42193167e-05, 7.47799641e-06, 1.49477273e-05],\n",
       "         [1.22596975e-05, 1.90600986e-05, 1.12027628e-05,\n",
       "          9.99907732e-01, 1.51105924e-05, 3.46098095e-05]],\n",
       "\n",
       "        [[1.96313486e-05, 1.76638132e-05, 9.99905646e-01,\n",
       "          2.32718885e-05, 2.02271622e-05, 1.35969603e-05],\n",
       "         [1.27303647e-05, 1.98436901e-05, 1.54660083e-05,\n",
       "          1.80900097e-05, 1.20208133e-05, 9.99921858e-01],\n",
       "         [1.86536927e-05, 9.99908209e-01, 1.64356316e-05,\n",
       "          2.42460519e-05, 1.80506613e-05, 1.44391088e-05],\n",
       "         ...,\n",
       "         [8.84052133e-06, 1.60019845e-05, 8.05978198e-06,\n",
       "          9.99917269e-01, 2.00290233e-05, 2.97471415e-05],\n",
       "         [6.31716102e-06, 1.71366846e-05, 9.99909699e-01,\n",
       "          1.69565901e-05, 1.71683496e-05, 3.27236485e-05],\n",
       "         [1.48813706e-05, 1.51053537e-05, 1.26186060e-05,\n",
       "          9.99909282e-01, 3.29150353e-05, 1.50718261e-05]]],\n",
       "\n",
       "\n",
       "       [[[1.24804792e-05, 9.99831319e-01, 7.46473670e-05,\n",
       "          2.95273494e-05, 3.20523977e-05, 1.98147027e-05],\n",
       "         [2.58358195e-05, 8.90216324e-06, 2.00988725e-05,\n",
       "          2.01486982e-05, 9.99903917e-01, 2.10229773e-05],\n",
       "         [8.54360405e-06, 1.62712531e-05, 2.12511513e-05,\n",
       "          9.99911964e-01, 3.29804607e-05, 8.94395635e-06],\n",
       "         ...,\n",
       "         [3.18276579e-05, 3.94373201e-05, 2.12984160e-05,\n",
       "          2.07116827e-05, 2.38672365e-05, 9.99862850e-01],\n",
       "         [7.37281516e-06, 1.38084870e-05, 2.26206612e-05,\n",
       "          2.81534158e-05, 1.63592631e-05, 9.99911666e-01],\n",
       "         [3.91695648e-05, 1.48522668e-05, 2.08830461e-05,\n",
       "          1.20190671e-05, 9.99898255e-01, 1.47747342e-05]],\n",
       "\n",
       "        [[4.42189048e-06, 3.27914022e-05, 1.98965427e-05,\n",
       "          1.99307688e-05, 9.99901533e-01, 2.13882886e-05],\n",
       "         [2.89408490e-05, 2.13697786e-05, 9.99900579e-01,\n",
       "          2.11345032e-05, 1.31016131e-05, 1.48857944e-05],\n",
       "         [2.46984418e-05, 2.11929437e-05, 9.99903679e-01,\n",
       "          1.26959058e-05, 1.74898887e-05, 2.02783849e-05],\n",
       "         ...,\n",
       "         [2.32257880e-05, 9.99923229e-01, 1.63265504e-05,\n",
       "          1.47618121e-05, 5.88758849e-06, 1.65164238e-05],\n",
       "         [1.12081179e-05, 1.37643656e-05, 1.07474625e-05,\n",
       "          9.99917090e-01, 2.18586065e-05, 2.53857579e-05],\n",
       "         [2.33012252e-05, 1.37344468e-05, 9.99919653e-01,\n",
       "          1.66973332e-05, 1.68130500e-05, 9.77795571e-06]],\n",
       "\n",
       "        [[1.91436848e-05, 1.70033891e-05, 1.74893066e-05,\n",
       "          2.35626940e-05, 9.99902070e-01, 2.06844416e-05],\n",
       "         [1.44836958e-05, 1.41622731e-05, 9.99894321e-01,\n",
       "          3.02237459e-05, 2.08832789e-05, 2.57981010e-05],\n",
       "         [1.44277001e-05, 3.35997902e-05, 9.99900460e-01,\n",
       "          1.50132691e-05, 1.87009573e-05, 1.77902402e-05],\n",
       "         ...,\n",
       "         [1.73663720e-05, 9.99923348e-01, 1.37563329e-05,\n",
       "          7.52927735e-06, 2.14730389e-05, 1.65629899e-05],\n",
       "         [1.66697428e-05, 1.81477517e-05, 1.28293177e-05,\n",
       "          9.99903917e-01, 1.84592791e-05, 2.99951062e-05],\n",
       "         [2.06853729e-05, 2.19079666e-05, 9.99886036e-01,\n",
       "          2.66581774e-05, 2.80649401e-05, 1.67135149e-05]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.83233060e-05, 1.92445004e-05, 2.54774932e-05,\n",
       "          9.99911129e-01, 1.56483147e-05, 1.02603226e-05],\n",
       "         [1.60390045e-05, 1.77515903e-05, 1.82130607e-05,\n",
       "          2.68367585e-05, 1.58607727e-05, 9.99905288e-01],\n",
       "         [2.52840109e-05, 9.99914527e-01, 1.08414097e-05,\n",
       "          1.58315524e-05, 2.07177363e-05, 1.27680833e-05],\n",
       "         ...,\n",
       "         [1.06143998e-05, 1.64116500e-05, 1.93822198e-05,\n",
       "          2.64057890e-05, 2.29259022e-05, 9.99904275e-01],\n",
       "         [9.35205026e-06, 1.63685763e-05, 1.40056945e-05,\n",
       "          2.02592928e-05, 2.25612894e-05, 9.99917448e-01],\n",
       "         [1.02461781e-05, 1.29519030e-05, 1.78845366e-05,\n",
       "          2.78467778e-05, 9.99905348e-01, 2.56411731e-05]],\n",
       "\n",
       "        [[1.19064935e-05, 1.76304020e-05, 1.08362874e-05,\n",
       "          9.99909520e-01, 1.98450871e-05, 3.03490087e-05],\n",
       "         [2.98328232e-05, 1.73472799e-05, 1.58824259e-05,\n",
       "          2.04008538e-05, 1.36801973e-05, 9.99902844e-01],\n",
       "         [2.78542284e-05, 3.76960030e-04, 9.99355137e-01,\n",
       "          6.22023363e-05, 1.40417251e-04, 3.75090167e-05],\n",
       "         ...,\n",
       "         [1.92510197e-05, 2.02436931e-05, 1.74053712e-05,\n",
       "          1.24013750e-05, 1.32998684e-05, 9.99917388e-01],\n",
       "         [6.49807043e-06, 2.83902045e-05, 1.46427192e-05,\n",
       "          2.02169176e-05, 2.09115678e-05, 9.99909341e-01],\n",
       "         [1.56091992e-05, 2.15165783e-05, 1.20890327e-05,\n",
       "          2.45324336e-05, 9.99898553e-01, 2.76982319e-05]],\n",
       "\n",
       "        [[1.86896650e-05, 1.24393264e-05, 1.59522751e-05,\n",
       "          9.99901533e-01, 3.01387627e-05, 2.12960877e-05],\n",
       "         [2.34174076e-05, 1.48944091e-05, 1.55025627e-05,\n",
       "          1.19921751e-05, 1.53273577e-05, 9.99918878e-01],\n",
       "         [2.50760932e-05, 6.61642756e-04, 9.99212861e-01,\n",
       "          3.04435380e-05, 4.06207982e-05, 2.92990590e-05],\n",
       "         ...,\n",
       "         [1.29663385e-05, 9.84751387e-06, 5.89113915e-06,\n",
       "          3.93944792e-05, 1.79019989e-05, 9.99913990e-01],\n",
       "         [1.34041766e-05, 2.68956646e-05, 1.29137188e-05,\n",
       "          1.30153494e-05, 2.18565110e-05, 9.99911964e-01],\n",
       "         [3.32692871e-05, 3.26622976e-05, 3.48975882e-05,\n",
       "          2.30727019e-05, 9.99849021e-01, 2.70614401e-05]]],\n",
       "\n",
       "\n",
       "       ...,\n",
       "\n",
       "\n",
       "       [[[2.32998282e-05, 6.05224050e-05, 9.99857783e-01,\n",
       "          1.79077033e-05, 2.25587282e-05, 1.77975744e-05],\n",
       "         [1.11234840e-05, 2.82875262e-05, 9.19686863e-06,\n",
       "          9.99901175e-01, 1.52363209e-05, 3.50156333e-05],\n",
       "         [6.88427826e-06, 1.85808167e-05, 2.21440569e-05,\n",
       "          9.99910176e-01, 2.47524586e-05, 1.75338937e-05],\n",
       "         ...,\n",
       "         [6.71506859e-06, 1.59121118e-05, 1.64775411e-05,\n",
       "          2.47808639e-05, 2.10590661e-05, 9.99915004e-01],\n",
       "         [9.99908686e-01, 2.70516612e-05, 2.59757508e-05,\n",
       "          1.08493259e-05, 1.87732512e-05, 8.73964746e-06],\n",
       "         [2.48965807e-05, 9.99915421e-01, 9.93534923e-06,\n",
       "          1.71981519e-05, 2.22690869e-05, 1.03523489e-05]],\n",
       "\n",
       "        [[1.57187460e-05, 3.99225391e-05, 9.99891281e-01,\n",
       "          2.22418457e-05, 1.68066472e-05, 1.41044147e-05],\n",
       "         [2.35920306e-05, 1.61199132e-05, 1.39018521e-05,\n",
       "          9.99915719e-01, 1.48745021e-05, 1.58513431e-05],\n",
       "         [2.09093560e-05, 3.77178658e-05, 1.41061610e-05,\n",
       "          9.99900937e-01, 1.44172227e-05, 1.19907781e-05],\n",
       "         ...,\n",
       "         [8.88592331e-06, 3.23944259e-05, 1.08904205e-05,\n",
       "          2.23494135e-05, 1.95776811e-05, 9.99905884e-01],\n",
       "         [9.99899387e-01, 1.99365895e-05, 3.34989745e-05,\n",
       "          9.15548299e-06, 1.09934481e-05, 2.70497985e-05],\n",
       "         [2.22076196e-05, 9.99903560e-01, 2.99408566e-05,\n",
       "          1.55246817e-05, 1.36895105e-05, 1.52018620e-05]],\n",
       "\n",
       "        [[3.54102813e-05, 9.99903798e-01, 1.26308296e-05,\n",
       "          2.41457019e-05, 1.26630766e-05, 1.13246497e-05],\n",
       "         [3.03157140e-05, 1.96136534e-05, 1.02058984e-05,\n",
       "          1.28261745e-05, 1.96029432e-05, 9.99907434e-01],\n",
       "         [1.89901330e-05, 1.76184112e-05, 9.99890268e-01,\n",
       "          1.25170918e-05, 2.81463144e-05, 3.25664878e-05],\n",
       "         ...,\n",
       "         [2.25026160e-05, 9.94594302e-06, 1.86789548e-05,\n",
       "          2.26751436e-05, 1.73514709e-05, 9.99908864e-01],\n",
       "         [9.99892652e-01, 1.84521778e-05, 2.55641644e-05,\n",
       "          3.00798565e-05, 8.78522405e-06, 2.45703850e-05],\n",
       "         [1.53766014e-05, 9.99912262e-01, 1.10912370e-05,\n",
       "          9.38127050e-06, 3.24116554e-05, 1.94372842e-05]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.29106920e-05, 9.99909163e-01, 2.89077871e-05,\n",
       "          1.51123386e-05, 1.89841958e-05, 1.49946427e-05],\n",
       "         [2.25349795e-05, 9.85886436e-06, 2.04513781e-05,\n",
       "          1.02770282e-05, 2.36844644e-05, 9.99913216e-01],\n",
       "         [1.88810518e-05, 1.59085030e-05, 9.99921262e-01,\n",
       "          1.66485552e-05, 2.03112140e-05, 7.07129948e-06],\n",
       "         ...,\n",
       "         [2.19088979e-05, 1.78511254e-05, 1.83404190e-05,\n",
       "          1.18467724e-05, 7.16099748e-06, 9.99922872e-01],\n",
       "         [9.99908328e-01, 2.25189142e-05, 1.54618174e-05,\n",
       "          1.62264332e-05, 1.89328566e-05, 1.85095705e-05],\n",
       "         [2.66470015e-05, 9.99911964e-01, 1.16764568e-05,\n",
       "          2.00283248e-05, 1.59605406e-05, 1.38519099e-05]],\n",
       "\n",
       "        [[2.52911123e-05, 1.99279748e-05, 2.32737511e-05,\n",
       "          1.92872249e-05, 1.03818020e-05, 9.99901772e-01],\n",
       "         [1.97917689e-05, 1.74747547e-05, 1.27868261e-05,\n",
       "          3.17941885e-05, 7.91315688e-06, 9.99910235e-01],\n",
       "         [2.71082390e-05, 1.79775525e-05, 9.99903977e-01,\n",
       "          2.69177835e-05, 1.46308448e-05, 9.33697447e-06],\n",
       "         ...,\n",
       "         [9.99860168e-01, 1.56465103e-05, 1.95900211e-05,\n",
       "          1.68069964e-05, 6.79837540e-05, 1.98847847e-05],\n",
       "         [9.99911487e-01, 1.02227787e-05, 1.03976345e-05,\n",
       "          2.47433782e-05, 2.18506902e-05, 2.12131999e-05],\n",
       "         [1.79646304e-05, 9.99917209e-01, 1.01807527e-05,\n",
       "          2.74816994e-05, 6.19282946e-06, 2.10676808e-05]],\n",
       "\n",
       "        [[1.90449646e-05, 9.99906003e-01, 2.40507070e-05,\n",
       "          1.06207444e-05, 2.27899291e-05, 1.75613677e-05],\n",
       "         [2.75862403e-05, 9.79600009e-06, 2.48395372e-05,\n",
       "          1.80546194e-05, 4.40265285e-06, 9.99915361e-01],\n",
       "         [3.02924309e-05, 2.10050493e-05, 9.99893844e-01,\n",
       "          1.03672501e-05, 2.56833155e-05, 1.88659178e-05],\n",
       "         ...,\n",
       "         [1.86159741e-05, 1.64457597e-05, 1.44420192e-05,\n",
       "          1.80114293e-05, 1.42264180e-05, 9.99918282e-01],\n",
       "         [9.99921143e-01, 1.68060651e-05, 7.21483957e-06,\n",
       "          4.36193659e-06, 2.75091734e-05, 2.30029691e-05],\n",
       "         [2.40919180e-05, 9.99915063e-01, 2.13701278e-05,\n",
       "          1.22111524e-05, 1.84770906e-05, 8.85548070e-06]]],\n",
       "\n",
       "\n",
       "       [[[6.22391235e-06, 1.49070984e-05, 3.39220278e-05,\n",
       "          2.08918937e-05, 9.99911606e-01, 1.25163933e-05],\n",
       "         [9.75170406e-06, 1.97414774e-05, 2.77035870e-05,\n",
       "          9.99909282e-01, 1.49006955e-05, 1.86449615e-05],\n",
       "         [1.90789578e-05, 5.05711650e-05, 2.70012533e-05,\n",
       "          9.97833073e-01, 2.05556653e-03, 1.46665843e-05],\n",
       "         ...,\n",
       "         [2.05442775e-05, 1.66455284e-05, 1.11557310e-05,\n",
       "          9.99930441e-01, 1.77497277e-05, 3.40864062e-06],\n",
       "         [3.39411199e-05, 9.33947740e-06, 2.67312862e-05,\n",
       "          1.10588735e-05, 7.39301322e-06, 9.99911487e-01],\n",
       "         [3.21117695e-05, 1.99256465e-05, 9.99913990e-01,\n",
       "          1.12821581e-05, 8.55693361e-06, 1.42090721e-05]],\n",
       "\n",
       "        [[9.99911249e-01, 1.81469368e-05, 1.67401740e-05,\n",
       "          1.21071935e-05, 2.51340680e-05, 1.66243408e-05],\n",
       "         [9.99910057e-01, 1.96408946e-05, 2.08301935e-05,\n",
       "          1.54726440e-05, 1.66365644e-05, 1.74016459e-05],\n",
       "         [2.26057600e-05, 1.92687148e-05, 3.31483316e-05,\n",
       "          1.71213178e-05, 2.41443049e-05, 9.99883652e-01],\n",
       "         ...,\n",
       "         [8.49144999e-06, 7.94453081e-06, 3.86007596e-05,\n",
       "          9.99910414e-01, 1.72262080e-05, 1.74007146e-05],\n",
       "         [2.76050996e-05, 1.19750621e-05, 1.86676625e-05,\n",
       "          9.99903619e-01, 1.71788270e-05, 2.09794380e-05],\n",
       "         [2.88265292e-05, 2.18893401e-05, 2.36304710e-04,\n",
       "          3.48018948e-05, 9.99663651e-01, 1.45486556e-05]],\n",
       "\n",
       "        [[2.42639799e-05, 9.62179620e-05, 9.99804020e-01,\n",
       "          8.39686254e-06, 3.69739719e-05, 3.00118700e-05],\n",
       "         [1.05493818e-04, 1.89252896e-05, 1.01493206e-05,\n",
       "          4.07252228e-05, 3.56121454e-05, 9.99789059e-01],\n",
       "         [1.88971288e-04, 1.86808985e-02, 2.34097359e-04,\n",
       "          9.79306638e-01, 1.54980528e-03, 3.96914547e-05],\n",
       "         ...,\n",
       "         [2.55831983e-05, 2.15480104e-05, 1.64690427e-05,\n",
       "          9.99893963e-01, 2.49545556e-05, 1.74923334e-05],\n",
       "         [1.83051452e-05, 2.94824131e-05, 4.67274804e-05,\n",
       "          9.99864101e-01, 1.80884963e-05, 2.32959865e-05],\n",
       "         [1.43783400e-05, 2.29820143e-05, 9.99891996e-01,\n",
       "          2.23293900e-05, 1.78783666e-05, 3.04074492e-05]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[2.13938765e-05, 2.52721366e-05, 2.26423144e-05,\n",
       "          9.99891758e-01, 2.70023011e-05, 1.19340839e-05],\n",
       "         [9.99913037e-01, 1.31808920e-05, 3.59443948e-05,\n",
       "          1.06069492e-05, 1.75460009e-05, 9.67615051e-06],\n",
       "         [1.24349026e-05, 3.35949357e-04, 2.52710888e-05,\n",
       "          1.64192170e-05, 9.99469101e-01, 1.40806427e-04],\n",
       "         ...,\n",
       "         [3.30749899e-05, 1.04373321e-05, 2.32756138e-05,\n",
       "          9.99904096e-01, 1.07444357e-05, 1.83513621e-05],\n",
       "         [1.89134153e-05, 2.92586628e-05, 1.60795171e-05,\n",
       "          1.89440325e-05, 9.63185448e-06, 9.99907196e-01],\n",
       "         [2.21824739e-05, 1.50341075e-05, 9.99915898e-01,\n",
       "          1.47604151e-05, 5.83159272e-06, 2.63266265e-05]],\n",
       "\n",
       "        [[2.40779482e-05, 3.50920018e-05, 2.11254228e-05,\n",
       "          9.99892890e-01, 1.78734772e-05, 8.94872937e-06],\n",
       "         [9.99909103e-01, 2.23186798e-05, 2.44430266e-05,\n",
       "          2.16816552e-05, 8.67020572e-06, 1.37723982e-05],\n",
       "         [1.46076782e-05, 2.99267005e-04, 2.74446793e-05,\n",
       "          2.71296594e-05, 9.99466896e-01, 1.64626981e-04],\n",
       "         ...,\n",
       "         [6.03881199e-06, 2.46155541e-05, 9.91520938e-06,\n",
       "          9.99923348e-01, 8.13172664e-06, 2.79683154e-05],\n",
       "         [2.21442897e-05, 1.63353980e-05, 2.51745805e-05,\n",
       "          1.89748826e-05, 9.58202872e-06, 9.99907732e-01],\n",
       "         [2.76835635e-05, 1.97507907e-05, 9.99898911e-01,\n",
       "          8.34878301e-06, 1.51082641e-05, 3.01504042e-05]],\n",
       "\n",
       "        [[3.43474094e-05, 2.67596915e-05, 2.12443992e-05,\n",
       "          9.99879539e-01, 1.87433325e-05, 1.93871092e-05],\n",
       "         [9.99914587e-01, 1.80061907e-05, 2.57359352e-05,\n",
       "          1.84798846e-05, 9.52801201e-06, 1.36948656e-05],\n",
       "         [3.45676672e-05, 3.01628141e-04, 2.55121849e-05,\n",
       "          2.75655184e-05, 9.99435186e-01, 1.75558031e-04],\n",
       "         ...,\n",
       "         [1.87025871e-05, 2.09382270e-05, 7.58550595e-06,\n",
       "          9.99913454e-01, 2.70584133e-05, 1.22884521e-05],\n",
       "         [1.67789403e-05, 1.32359564e-05, 2.62050889e-05,\n",
       "          1.38534233e-05, 1.97491609e-05, 9.99910176e-01],\n",
       "         [1.85540412e-05, 2.97324732e-05, 9.99910235e-01,\n",
       "          1.20775658e-05, 1.38314208e-05, 1.55537855e-05]]],\n",
       "\n",
       "\n",
       "       [[[2.41535599e-05, 2.08404381e-05, 4.56827693e-05,\n",
       "          9.99858558e-01, 2.08305428e-05, 2.98807863e-05],\n",
       "         [1.64258527e-05, 9.99894381e-01, 1.64512312e-05,\n",
       "          2.59310473e-05, 2.78713414e-05, 1.89223792e-05],\n",
       "         [1.18353637e-05, 1.83938537e-05, 1.56082679e-05,\n",
       "          9.99910474e-01, 1.89184211e-05, 2.48353463e-05],\n",
       "         ...,\n",
       "         [1.20492186e-05, 1.63505320e-05, 1.84538076e-05,\n",
       "          9.99909639e-01, 1.07281958e-05, 3.28072347e-05],\n",
       "         [2.04520766e-05, 9.99908924e-01, 1.18543394e-05,\n",
       "          1.68933766e-05, 1.12913549e-05, 3.06258444e-05],\n",
       "         [1.20145269e-05, 9.99914885e-01, 2.22586095e-05,\n",
       "          1.53972069e-05, 1.50416745e-05, 2.03179661e-05]],\n",
       "\n",
       "        [[3.34994402e-05, 3.88356857e-05, 1.72678847e-05,\n",
       "          2.19440553e-05, 1.00401230e-05, 9.99878347e-01],\n",
       "         [2.29855068e-05, 5.17319422e-05, 9.99880552e-01,\n",
       "          1.05670770e-05, 1.37954485e-05, 2.03563832e-05],\n",
       "         [9.99833584e-01, 2.41496600e-05, 1.80423958e-05,\n",
       "          1.10131805e-05, 9.52857081e-05, 1.79490307e-05],\n",
       "         ...,\n",
       "         [3.21727712e-05, 1.45413214e-05, 1.69028062e-05,\n",
       "          1.73858134e-05, 9.99905169e-01, 1.37557508e-05],\n",
       "         [1.58133917e-05, 9.99912739e-01, 3.09732277e-05,\n",
       "          1.93630112e-05, 1.13807619e-05, 9.63959610e-06],\n",
       "         [2.52760947e-05, 3.26088630e-05, 9.99897838e-01,\n",
       "          1.37623865e-05, 9.37178265e-06, 2.10986473e-05]],\n",
       "\n",
       "        [[3.94671224e-05, 5.96600585e-05, 1.70554267e-05,\n",
       "          9.99836385e-01, 2.26576813e-05, 2.46989075e-05],\n",
       "         [2.10960861e-05, 9.99861538e-01, 3.93030932e-05,\n",
       "          2.14357860e-05, 4.22199955e-05, 1.42703066e-05],\n",
       "         [9.99862671e-01, 2.93715857e-05, 2.06250697e-05,\n",
       "          4.53455141e-06, 6.24817330e-05, 2.03375239e-05],\n",
       "         ...,\n",
       "         [2.09624413e-05, 3.16365622e-05, 2.33035535e-05,\n",
       "          9.99876559e-01, 2.32944731e-05, 2.41668895e-05],\n",
       "         [1.19021861e-05, 9.99899387e-01, 2.67035794e-05,\n",
       "          1.73276057e-05, 1.97528861e-05, 2.49245204e-05],\n",
       "         [4.38569114e-05, 9.99890268e-01, 1.38507457e-05,\n",
       "          1.69884879e-05, 1.97708141e-05, 1.52224675e-05]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[1.32559799e-05, 1.16948504e-05, 7.39545794e-06,\n",
       "          4.62713651e-05, 9.99907672e-01, 1.36961462e-05],\n",
       "         [1.81827927e-05, 9.99911547e-01, 2.25170515e-05,\n",
       "          1.20609766e-05, 1.39293261e-05, 2.18739733e-05],\n",
       "         [1.73342414e-05, 6.82851532e-06, 9.99900579e-01,\n",
       "          2.45096162e-05, 3.20619438e-05, 1.87027035e-05],\n",
       "         ...,\n",
       "         [9.99864578e-01, 7.53893983e-06, 1.52182765e-05,\n",
       "          2.20502261e-05, 7.60662369e-05, 1.45836966e-05],\n",
       "         [1.63267832e-05, 9.99911547e-01, 1.80173665e-05,\n",
       "          1.60373747e-05, 2.51200981e-05, 1.30046392e-05],\n",
       "         [2.80085951e-05, 2.04287935e-05, 1.57513423e-05,\n",
       "          1.16864685e-05, 1.15110306e-05, 9.99912560e-01]],\n",
       "\n",
       "        [[2.35920306e-05, 2.56763306e-05, 1.01339538e-05,\n",
       "          9.99910772e-01, 1.18189491e-05, 1.80443749e-05],\n",
       "         [1.70032727e-05, 9.99911308e-01, 2.07507983e-05,\n",
       "          1.21984631e-05, 8.46543116e-06, 3.02686822e-05],\n",
       "         [3.20265535e-05, 2.25193799e-05, 9.99905109e-01,\n",
       "          8.89558578e-06, 1.23319915e-05, 1.91631261e-05],\n",
       "         ...,\n",
       "         [2.78591178e-05, 1.60421478e-05, 1.40310731e-05,\n",
       "          9.99906898e-01, 1.32841524e-05, 2.19680369e-05],\n",
       "         [4.32814704e-06, 9.99920130e-01, 1.09986868e-05,\n",
       "          2.87513249e-05, 1.27686653e-05, 2.30178703e-05],\n",
       "         [1.36704184e-05, 7.90087506e-06, 1.63314398e-05,\n",
       "          1.86496181e-05, 2.42041424e-05, 9.99919236e-01]],\n",
       "\n",
       "        [[2.24874821e-05, 1.24104554e-05, 2.02332158e-05,\n",
       "          5.30394027e-06, 9.99912262e-01, 2.73340847e-05],\n",
       "         [2.25186814e-05, 9.99902010e-01, 1.56338792e-05,\n",
       "          5.31901605e-06, 2.16639601e-05, 3.28265596e-05],\n",
       "         [2.24392861e-05, 1.87795376e-05, 9.99911010e-01,\n",
       "          5.19608147e-06, 2.20516231e-05, 2.05603428e-05],\n",
       "         ...,\n",
       "         [4.14806418e-05, 1.31921843e-05, 9.83459176e-06,\n",
       "          1.38004543e-05, 9.99897420e-01, 2.42290553e-05],\n",
       "         [1.00218458e-05, 9.99923348e-01, 2.13840976e-05,\n",
       "          1.34247821e-05, 1.20276818e-05, 1.98590569e-05],\n",
       "         [2.16935296e-05, 1.43436482e-05, 1.53055880e-05,\n",
       "          1.00110192e-05, 2.71268655e-05, 9.99911547e-01]]]],      dtype=float32)"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "key, subkey = jax.random.split(config.jax_key)\n",
    "config.jax_key = key\n",
    "\n",
    "sample = buffer.sample(buffer_list, subkey)\n",
    "sample = reshape_diffusion_setup(sample, subkey)\n",
    "\n",
    "\n",
    "result = sampling_model(key=config.jax_key, model=transformer, sample_eval=sample, config=config, nb_step=100)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[4, 0, 2],\n",
       "        [1, 0, 5],\n",
       "        [3, 2, 2]],\n",
       "\n",
       "       [[4, 3, 0],\n",
       "        [3, 1, 1],\n",
       "        [5, 5, 4]],\n",
       "\n",
       "       [[1, 3, 3],\n",
       "        [0, 2, 5],\n",
       "        [3, 0, 5]],\n",
       "\n",
       "       [[0, 3, 1],\n",
       "        [4, 3, 1],\n",
       "        [1, 4, 2]],\n",
       "\n",
       "       [[0, 2, 5],\n",
       "        [5, 4, 4],\n",
       "        [3, 4, 1]],\n",
       "\n",
       "       [[4, 2, 0],\n",
       "        [1, 5, 2],\n",
       "        [5, 0, 2]]], dtype=int32)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index_batch  = 64\n",
    "\n",
    "jnp.argmax(sample[\"state_past\"], axis=-1).reshape((128, 8, 6, 3, 3))[index_batch, -1, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[2, 5, 2],\n",
       "        [0, 0, 2],\n",
       "        [4, 1, 3]],\n",
       "\n",
       "       [[0, 2, 5],\n",
       "        [3, 1, 1],\n",
       "        [5, 5, 4]],\n",
       "\n",
       "       [[4, 3, 0],\n",
       "        [0, 2, 5],\n",
       "        [3, 0, 5]],\n",
       "\n",
       "       [[1, 3, 3],\n",
       "        [4, 3, 1],\n",
       "        [1, 4, 2]],\n",
       "\n",
       "       [[0, 3, 1],\n",
       "        [5, 4, 4],\n",
       "        [3, 4, 1]],\n",
       "\n",
       "       [[4, 2, 0],\n",
       "        [1, 5, 2],\n",
       "        [5, 0, 2]]], dtype=int32)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.argmax(result, axis=-1).reshape((128, 24, 6, 3, 3))[index_batch, 0, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Array([[[3, 5, 0],\n",
       "        [0, 0, 2],\n",
       "        [4, 1, 3]],\n",
       "\n",
       "       [[0, 2, 5],\n",
       "        [3, 1, 1],\n",
       "        [5, 5, 4]],\n",
       "\n",
       "       [[4, 3, 2],\n",
       "        [0, 2, 5],\n",
       "        [3, 0, 2]],\n",
       "\n",
       "       [[3, 1, 2],\n",
       "        [3, 3, 4],\n",
       "        [1, 4, 1]],\n",
       "\n",
       "       [[5, 3, 1],\n",
       "        [0, 4, 4],\n",
       "        [2, 4, 1]],\n",
       "\n",
       "       [[4, 2, 0],\n",
       "        [1, 5, 2],\n",
       "        [5, 5, 0]]], dtype=int32)"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jnp.argmax(result, axis=-1).reshape((128, 24, 6, 3, 3))[index_batch, 1, :, :, :]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'action_pred'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[35], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m sample \u001b[38;5;241m=\u001b[39m buffer_eval\u001b[38;5;241m.\u001b[39msample(buffer_list_eval, subkey)\n\u001b[0;32m----> 2\u001b[0m sample \u001b[38;5;241m=\u001b[39m \u001b[43mreshape_sample\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/rubikscubesolver/rubiktransformer/trainer.py:334\u001b[0m, in \u001b[0;36mreshape_sample\u001b[0;34m(sample)\u001b[0m\n\u001b[1;32m    331\u001b[0m one_hot_0 \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mone_hot(sample\u001b[38;5;241m.\u001b[39mexperience[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, :, \u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m6\u001b[39m)\n\u001b[1;32m    332\u001b[0m one_hot_1 \u001b[38;5;241m=\u001b[39m jax\u001b[38;5;241m.\u001b[39mnn\u001b[38;5;241m.\u001b[39mone_hot(sample\u001b[38;5;241m.\u001b[39mexperience[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m][:, :, \u001b[38;5;241m2\u001b[39m], \u001b[38;5;241m3\u001b[39m)\n\u001b[0;32m--> 334\u001b[0m sample\u001b[38;5;241m.\u001b[39mexperience[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124maction\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[43msample\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mexperience\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43maction_pred\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[1;32m    336\u001b[0m \u001b[38;5;66;03m# reward have to go from (batch_size, seq_len) to (batch_size, seq_len, 1)\u001b[39;00m\n\u001b[1;32m    337\u001b[0m sample\u001b[38;5;241m.\u001b[39mexperience[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m sample\u001b[38;5;241m.\u001b[39mexperience[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mreshape(\n\u001b[1;32m    338\u001b[0m     sample\u001b[38;5;241m.\u001b[39mexperience[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreward\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m    339\u001b[0m )\n",
      "\u001b[0;31mKeyError\u001b[0m: 'action_pred'"
     ]
    }
   ],
   "source": [
    "sample = buffer_eval.sample(buffer_list_eval, subkey)\n",
    "sample = reshape_sample(sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_past_state_with_with_random_policy(key, vmap_reset, step_jit_env, config):\n",
    "    \"\"\"\n",
    "    Generate past state with random policy\n",
    "\n",
    "    Args:\n",
    "        config: configuration object\n",
    "\n",
    "    Returns:\n",
    "        state_past: (batch_size, len_seq//4, 6, 3, 3)\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    key1, key2 = jax.random.split(config.jax_key)\n",
    "\n",
    "    keys = jax.random.split(key1, config.batch_size)\n",
    "    state, timestep = vmap_reset(keys)\n",
    "\n",
    "    last_state = None\n",
    "    past_state = []\n",
    "\n",
    "    actions_all = jax.random.randint(\n",
    "        key=config.jax_key,\n",
    "        minval=env.action_spec.minimum,\n",
    "        maxval=env.action_spec.maximum,\n",
    "        shape=(config.batch_size, config.len_seq // 4, 3),\n",
    "    )\n",
    "\n",
    "    for i in range(config.len_seq // 4):\n",
    "\n",
    "        # apply random policy and retrieve state\n",
    "        action = actions_all[:, i, :]\n",
    "\n",
    "        state, timestep  = step_jit_env(state, action)\n",
    "        past_state.append(state.cube)\n",
    "\n",
    "    # concat all the past state to get the shape (batch_size, len_seq//4, 6, 3, 3) from a list of state of size (batch_size, 6, 3, 3) by creating the 1 axis\n",
    "    state_past = jnp.stack(past_state, axis=1)\n",
    "\n",
    "    return state_past, state, actions_all\n",
    "\n",
    "step_jit_env = jax.vmap(jit_step)\n",
    "\n",
    "state_past, state, actions_past = generate_past_state_with_with_random_policy(key, vmap_reset, step_jit_env, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(128, 8, 6, 3, 3)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state_past.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def apply_decision_diffuser_policy(key, state_past, decision_diffuser, inverse_rl_model, config, target_reward=0.5):\n",
    "    \"\"\"\n",
    "    1. Make a estimation of the targeted reward\n",
    "    2. Generate futur state with those targeted reward\n",
    "    3. Choose policy from that\n",
    "    \"\"\"\n",
    "    sample_eval = {\n",
    "        \"state_past\": jax.nn.one_hot(state_past, 6),\n",
    "    }\n",
    "\n",
    "    state_past = jnp.copy(state_past.reshape((state_past.shape[0], state_past.shape[1], -1)))\n",
    "    state_past = jax.nn.one_hot(state_past, num_classes=6)\n",
    "\n",
    "    state_future = sampling_model(key, decision_diffuser, sample_eval, nb_step=100, config=config, target_reward=target_reward)\n",
    "\n",
    "    # state_future is (batch_size, seq_len, dim_input_state / 6, 6)\n",
    "    state_to_act = jnp.concatenate([state_past, state_future], axis=1)\n",
    "    state_to_act_futur_t = state_to_act[:, (config.len_seq // 4 - 1):(-1), :, :]\n",
    "    state_to_act_futur_td1 = state_to_act[:, (config.len_seq // 4):, :, :]\n",
    "\n",
    "    # flatten the last 2 axis\n",
    "    state_to_act_futur_t = state_to_act_futur_t.reshape(\n",
    "        (state_to_act_futur_t.shape[0], state_to_act_futur_t.shape[1], -1)\n",
    "    )\n",
    "\n",
    "    state_to_act_futur_td1 = state_to_act_futur_td1.reshape(\n",
    "        (state_to_act_futur_td1.shape[0], state_to_act_futur_td1.shape[1], -1)\n",
    "    )\n",
    "\n",
    "    # now use reverse RL to compute the action TODO later\n",
    "    actions = inverse_rl_model(state_to_act_futur_t, state_to_act_futur_td1)\n",
    "\n",
    "    return actions\n",
    "\n",
    "actions_futur = apply_decision_diffuser_policy(config.jax_key, state_past, transformer, inverse_rl_model, config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from rubiktransformer.dataset import GOAL_OBSERVATION\n",
    "\n",
    "def gather_data_with_policy(state, state_past, actions_past, actions_futur, buffer, buffer_list, config):\n",
    "    \"\"\"\n",
    "    For loop with those policy and state\n",
    "\n",
    "    log performance compare to target\n",
    "\n",
    "    \"\"\"\n",
    "    state_futur_list = []\n",
    "\n",
    "    for i in range(config.len_seq - config.len_seq // 4):\n",
    "        actions_step = actions_futur[:, i, :]\n",
    "        actions_0 = jnp.argmax(actions_step[:, :6], axis=1)\n",
    "        actions_1 = jnp.argmax(actions_step[:, 6:], axis=1)\n",
    "\n",
    "        actions_full = jnp.stack([actions_0, jnp.zeros(config.batch_size), actions_1], axis=1)\n",
    "        \n",
    "        # transform to int type\n",
    "        actions_full = actions_full.astype(jnp.int32)\n",
    "    \n",
    "        # step \n",
    "        state, timestep  = step_jit_env(state, actions_full)\n",
    "\n",
    "        state_futur_list.append(state.cube)\n",
    "\n",
    "    # TODO SAVE DATA into batch format for later training\n",
    "    actions_0_all_futur = jnp.argmax(actions_futur[:, :, :6], axis=-1)\n",
    "    actions_1_all_futur = jnp.argmax(actions_futur[:, :, 6:], axis=-1)\n",
    "\n",
    "    action_all_futur = jnp.stack([actions_0_all_futur, jnp.zeros((config.batch_size, actions_0_all_futur.shape[1])), actions_1_all_futur], axis=-1)\n",
    "\n",
    "    action_all = jnp.concatenate([actions_past, action_all_futur], axis=1)\n",
    "    action_all = action_all.astype(jnp.int32)\n",
    "\n",
    "    state_futur = jnp.stack(state_futur_list, axis=1)\n",
    "\n",
    "    state_all = jnp.concatenate([state_past, state_futur], axis=1)\n",
    "\n",
    "    # compute reward \n",
    "    goal_observation = jnp.repeat(\n",
    "        GOAL_OBSERVATION[None, None, :, :, :], config.batch_size, axis=0\n",
    "    )\n",
    "    goal_observation = jnp.repeat(goal_observation, config.len_seq, axis=1)\n",
    "    reward = jnp.where(state_all != goal_observation, -1.0, 1.0)\n",
    "\n",
    "    reward = reward.mean(axis=[2, 3, 4])\n",
    "    reward = reward[:, -1] - reward[:, config.len_seq//4]\n",
    "\n",
    "\n",
    "    for idx_batch in range(config.batch_size):\n",
    "        buffer_list = buffer.add(\n",
    "            buffer_list,\n",
    "            {\n",
    "                \"action\": action_all[idx_batch],\n",
    "                \"reward\": reward[idx_batch],\n",
    "                \"state_histo\": state_all[idx_batch],\n",
    "            },\n",
    "        )\n",
    "\n",
    "    return buffer, buffer_list, reward\n",
    "\n",
    "buffer, buffer_list, reward_real = gather_data_with_policy(state, state_past, actions_past, actions_futur, buffer, buffer_list, config)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "begin iter\n",
      "generate high reward value\n",
      "apply the strategy\n",
      "improve data buffer\n",
      "new target :  0.41666666\n",
      "trainign\n",
      "{'loss': Array(0.10118264, dtype=float32), 'loss_cross_entropy': Array(0.09603005, dtype=float32)}\n",
      "begin iter\n",
      "generate high reward value\n",
      "apply the strategy\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Step only supports monotonically increasing values, use define_metric to set a custom x axis. For details see: https://wandb.me/define-metric\n",
      "\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m (User provided step: 0 is less than current step: 1871. Dropping entry: {'loss': 0.10118263959884644, 'loss_cross_entropy': 0.09603004902601242, '_timestamp': 1725712581.9509678}).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "improve data buffer\n",
      "new target :  0.375\n",
      "trainign\n",
      "begin iter\n",
      "generate high reward value\n",
      "apply the strategy\n",
      "improve data buffer\n",
      "new target :  0.3912037\n",
      "trainign\n",
      "begin iter\n",
      "generate high reward value\n",
      "apply the strategy\n"
     ]
    }
   ],
   "source": [
    "def reward_hacking(reward):\n",
    "    \"\"\"\n",
    "    reward is an array of value of shape (batch_size, len_seq, 1) with value between -1 and 1\n",
    "    we want to apply to every element the funciton\n",
    "    f(x) = 0.1 * jnp.exp(4 * x)\n",
    "    \"\"\"\n",
    "\n",
    "    return 0.1 * jnp.exp(4.0 * reward)\n",
    "\n",
    "def improve_training_loop(buffer, buffer_list, nb_iter=10000):\n",
    "    \"\"\"\n",
    "    Relaunch the training loop with those new data incorporated into the buffer\n",
    "    \n",
    "    Full stuff here\n",
    "    Online transformer setup\n",
    "\n",
    "    1. We generate env setup \n",
    "    2. First random action in the different env\n",
    "    3. Use decision_diffuser to choose the action to do from here\n",
    "    4. Observe / apply policy  to retrieve data\n",
    "    5. Add the data into the buffer\n",
    "    6. Train model on those data\n",
    "\n",
    "    Remember to log the performance data to compare with other run / algorithms\n",
    "    \"\"\"\n",
    "    target_reward = 0.5\n",
    "    \n",
    "    for idx_step in range(nb_iter):\n",
    "\n",
    "        print(\"begin iter\")\n",
    "\n",
    "        key, subkey = jax.random.split(config.jax_key)\n",
    "        config.jax_key = key\n",
    "\n",
    "        print(\"generate high reward value\")\n",
    "        # first generate random state\n",
    "        state_past, state, actions_past = generate_past_state_with_with_random_policy(key, vmap_reset, step_jit_env, config)\n",
    "        \n",
    "        print(\"apply the strategy\")\n",
    "        # apply model to get some generation\n",
    "        actions_futur = apply_decision_diffuser_policy(config.jax_key, state_past, transformer, inverse_rl_model, config)\n",
    "\n",
    "        print(\"improve data buffer\")\n",
    "        # update replay buffer dataset\n",
    "        buffer, buffer_list, reward_mean = gather_data_with_policy(state, state_past, actions_past, actions_futur, buffer, buffer_list, config)\n",
    "\n",
    "        diff_target = reward_mean - target_reward\n",
    "        target_reward = 1./2. * (target_reward + reward_mean.max())\n",
    "        print(\"new target : \", target_reward)\n",
    "\n",
    "        wandb.log({\"reward_normalized\" : reward_hacking(reward_mean).mean(), \"target_reward_new\" : target_reward, \"diff_target_reward\": diff_target.mean()})\n",
    "\n",
    "        # now we can do the training loop\n",
    "        sample = buffer.sample(buffer_list, subkey)\n",
    "        sample = reshape_diffusion_setup(sample, subkey)\n",
    "\n",
    "        print(\"trainign\")\n",
    "\n",
    "        # we update the policy\n",
    "        train_step_transformer_rf(\n",
    "            transformer, optimizer_diffuser, metrics_train, sample\n",
    "        )\n",
    "\n",
    "        if idx_step % config.log_every_step == 0:\n",
    "            metrics_train_result = metrics_train.compute()\n",
    "            print(metrics_train_result)\n",
    "\n",
    "            wandb.log(metrics_train_result, step=idx_step)\n",
    "            metrics_train.reset()\n",
    "\n",
    "improve_training_loop(buffer, buffer_list, nb_iter=10000)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
